# Name = 9_2a_tgt-s3-sink-insert-consultants.properties
# Owner = Saurav Mitra
# Sink = Oracle
# Connector = JdbcSinkConnector
# Scenario = Create Daily Files (consultants) in S3 from Kafka Topic (pg-bulk-consultants)
# Dependency = 2a_src-pg-jdbc-bulk-consultants.properties

name = tgt-s3-sink-insert-consultants
connector.class = io.confluent.connect.s3.S3SinkConnector
topics = pg-bulk-consultants
s3.bucket.name = ashnik-confluent-s3-sink
s3.region = ap-southeast-1
aws.access.key.id = XXXXXXXX
aws.secret.access.key = XXXXXXXX
storage.class = io.confluent.connect.s3.storage.S3Storage
format.class = io.confluent.connect.s3.format.json.JsonFormat
topics.dir = consultants
flush.size = 300
rotate.schedule.interval.ms = 60000
timezone = UTC
key.converter = org.apache.kafka.connect.storage.StringConverter
key.converter.schemas.enable = false
# value.converter = io.confluent.connect.avro.AvroConverter
# value.converter.schemas.enable = true
tasks.max = 1
